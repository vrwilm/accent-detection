{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ff97adf",
   "metadata": {},
   "source": [
    "![./img/sp_tiny.png](./img/sp_tiny.png)\n",
    "<h1><center>Accent Detection: <br>\n",
    "Signal Processing  + CNN</center></h1>\n",
    "<h3><center>Part 1: Getting the dataset</center></h3>\n",
    "<center>Group 2: Katerina Bosko and Victor Wilm\n",
    "<center>Northeastern University, CS6140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d5430d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from pydub import AudioSegment\n",
    "from urllib.request import urlretrieve\n",
    "import os\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403ad3a6",
   "metadata": {},
   "source": [
    "In this notebook, we scrape [Speech Accent Archive](http://accent.gmu.edu/) gathered by the George Mason University to get data for two languages sets:\n",
    "1) English, Russian, German, Mandarin <br>\n",
    "2) English, Russian, French, Arabic\n",
    "\n",
    "We are downloading data in wav format instead of compressed mp3 because most audio processing libraries support wav format better. \n",
    "\n",
    "Note that we do not provide the datasets because their size is very large (languages set 1 - 2GB, languages set 2 - 1.65 GB). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13dffe95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_languages() -> list:\n",
    "    \"\"\"\n",
    "    This function gets the list of languages from http://accent.gmu.edu/browse_language.php\n",
    "    and returns a list of languages\n",
    "    \"\"\"\n",
    "    url = \"http://accent.gmu.edu/browse_language.php\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    main_content = soup.find(id=\"maincontent\")\n",
    "    languages = [language.text for language in main_content.find_all(\"li\")]\n",
    "    return languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b161d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_language_urls(language: str) -> dict:\n",
    "    \"\"\"\n",
    "    This function finds all the urls for a given language\n",
    "    \"\"\"\n",
    "    url = f\"http://accent.gmu.edu/browse_language.php?function=find&language={language}\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    main_content = soup.find(id=\"maincontent\")\n",
    "    content = main_content.find(class_=\"content\")\n",
    "    samples = content.find_all(\"p\")\n",
    "    result = {}\n",
    "    for sample in samples:\n",
    "        result[sample.text.replace(\", \", \"_\")] = \"http://accent.gmu.edu/\" + sample.find(\"a\")[\"href\"]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "857c25da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio(data_path: str, url: str, folder: str, name: str) -> None:\n",
    "    \"\"\"\n",
    "    This function downloads the audio file from a given url\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    audio_url = \"http://accent.gmu.edu\" + soup.find(\"source\").get(\"src\")\n",
    "    (audio, headers) = urlretrieve(audio_url)\n",
    "    audio = AudioSegment.from_mp3(audio)\n",
    "    if not os.path.exists(f\"{data_path}/{folder}/\"):\n",
    "        os.makedirs(f\"{data_path}/{folder}/\")\n",
    "    audio.export(f\"{data_path}/{folder}/{name}.wav\", format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17ba22f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data(data_path, languages_chosen):\n",
    "    if not os.path.exists(data_path):\n",
    "        os.makedirs(data_path)\n",
    "    languages = get_languages()\n",
    "    for language in languages:\n",
    "        if language in languages_chosen:\n",
    "            print(f\"Downloading {language}...\")\n",
    "            urls = get_language_urls(language)\n",
    "            for name, url in urls.items():\n",
    "                time.sleep(random.randint(1, 5))\n",
    "                get_audio(data_path, url, language, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cf7fa1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading english...\n",
      "Downloading german...\n",
      "Downloading mandarin...\n",
      "Downloading russian...\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH_1 = \"./data/lang_set_1\"\n",
    "LANGUAGES_CHOSEN_1 = [\"english\", \"russian\", \"german\", \"mandarin\"]\n",
    "download_data(DATA_PATH_1, LANGUAGES_CHOSEN_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5b19b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_PATH_2 = \"./data/lang_set_2\"\n",
    "# LANGUAGES_CHOSEN_2 = [\"english\", \"russian\", \"arabic\", \"french\"]\n",
    "# download_data(DATA_PATH_2, LANGUAGES_CHOSEN_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022fa31d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
